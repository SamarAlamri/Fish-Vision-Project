{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_u2jW-Whe67Y",
        "outputId": "06379e5f-89ef-4d32-f7bb-4e58ec9c839e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2025.11.12)\n"
          ]
        }
      ],
      "source": [
        "!pip install kagglehub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZlDinBHfCyY",
        "outputId": "852a007c-886f-4abb-dc75-1162183afd0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/madhushreesannigrahi/fish-recognition-ground-truth-data?dataset_version_number=1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 457M/457M [00:06<00:00, 78.2MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset base path: /root/.cache/kagglehub/datasets/madhushreesannigrahi/fish-recognition-ground-truth-data/versions/1\n",
            "Copied 2500 images from fish_01\n",
            "Copied 2500 images from fish_02\n",
            "Copied 2500 images from fish_03\n",
            "Copied 2500 images from fish_04\n",
            "Copied 2500 images from fish_05\n",
            "Copied 450 images from fish_07\n",
            "fish_07 needs augmentation: 550 images\n",
            "Finished augmentation for fish_07: now 1000 images total\n",
            "===== Dataset Processing Complete =====\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img, array_to_img\n",
        "\n",
        "# Step 1 - Download the dataset\n",
        "path = kagglehub.dataset_download(\"madhushreesannigrahi/fish-recognition-ground-truth-data\")\n",
        "print(\"Dataset base path:\", path)\n",
        "\n",
        "# Step 2 - Folder that contains fish_**\n",
        "fish_image_path = os.path.join(path, \"fish_image\")\n",
        "\n",
        "# Step 3 - Classes you want\n",
        "selected_classes = [\"fish_01\", \"fish_02\", \"fish_03\", \"fish_04\", \"fish_05\", \"fish_07\"]\n",
        "\n",
        "# Step 4 - Destination folder\n",
        "new_dataset_path = \"/content/fish_selected_6_classes.5\"\n",
        "os.makedirs(new_dataset_path, exist_ok=True)\n",
        "\n",
        "# Create augmentation generator\n",
        "aug_gen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "TARGET_COUNT = 1000\n",
        "\n",
        "# Step 5 - Process each class\n",
        "for class_name in selected_classes:\n",
        "    src = os.path.join(fish_image_path, class_name)\n",
        "    dst = os.path.join(new_dataset_path, class_name)\n",
        "\n",
        "    if not os.path.exists(src):\n",
        "        print(f\"Class not found: {class_name}\")\n",
        "        continue\n",
        "\n",
        "    os.makedirs(dst, exist_ok=True)\n",
        "\n",
        "    # Get all images in the source folder\n",
        "    images = sorted(glob.glob(src + \"/*\"))\n",
        "\n",
        "    # Copy first 2500 images (or all if less)\n",
        "    copied_count = 0\n",
        "    for img_path in images[:2500]:\n",
        "        shutil.copy(img_path, dst)\n",
        "        copied_count += 1\n",
        "\n",
        "    print(f\"Copied {copied_count} images from {class_name}\")\n",
        "\n",
        "    # If less than 1000 images → use augmentation\n",
        "    if copied_count < TARGET_COUNT:\n",
        "        needed = TARGET_COUNT - copied_count\n",
        "        print(f\"{class_name} needs augmentation: {needed} images\")\n",
        "\n",
        "        img_files = glob.glob(dst + \"/*\")  # existing (copied) images\n",
        "\n",
        "        aug_count = 0\n",
        "        idx = 0\n",
        "\n",
        "        while aug_count < needed:\n",
        "            img = load_img(img_files[idx])\n",
        "            img_array = img_to_array(img)\n",
        "            img_array = img_array.reshape((1,) + img_array.shape)\n",
        "\n",
        "            # Generate 1 augmentation image at a time\n",
        "            for batch in aug_gen.flow(img_array, batch_size=1,\n",
        "                                      save_to_dir=dst,\n",
        "                                      save_prefix=\"aug\",\n",
        "                                      save_format=\"jpg\"):\n",
        "                aug_count += 1\n",
        "                break\n",
        "\n",
        "            idx = (idx + 1) % len(img_files)\n",
        "\n",
        "        print(f\"Finished augmentation for {class_name}: now 1000 images total\")\n",
        "\n",
        "print(\"===== Dataset Processing Complete =====\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEaqkzruggF6",
        "outputId": "8ab9429c-e847-4aed-8571-83fbdbc0b450"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "save_dir = \"/content/drive/MyDrive/fish_results.6c\"      # where results will be saved\n",
        "import os\n",
        "os.makedirs(save_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OovplD4XgoV9",
        "outputId": "2918338b-f8ce-4456-a27f-513afb115cd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total images: 13485\n",
            "Classes: ['fish_01', 'fish_02', 'fish_03', 'fish_04', 'fish_05', 'fish_07']\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "img_paths = []\n",
        "labels = []\n",
        "\n",
        "# Make sure paths are correct\n",
        "classes = sorted(os.listdir(new_dataset_path))\n",
        "\n",
        "# All image extensions you want to include\n",
        "extensions = [\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.JPG\", \"*.JPEG\", \"*.PNG\"]\n",
        "\n",
        "for class_name in classes:\n",
        "    class_folder = os.path.join(new_dataset_path, class_name)\n",
        "\n",
        "    for ext in extensions:\n",
        "        for img_file in glob.glob(os.path.join(class_folder, ext)):\n",
        "            img_paths.append(img_file)\n",
        "            labels.append(class_name)\n",
        "\n",
        "img_paths = np.array(img_paths)\n",
        "labels = np.array(labels)\n",
        "\n",
        "print(\"Total images:\", len(img_paths))\n",
        "print(\"Classes:\", classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pS0WPZGcgrp7",
        "outputId": "876d521a-6f04-43bb-a5e5-f5cfb7c09562"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of classes: 6\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_enc = LabelEncoder()\n",
        "labels_encoded = label_enc.fit_transform(labels)\n",
        "\n",
        "num_classes = len(label_enc.classes_)\n",
        "print(\"Number of classes:\", num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEds4oYCwZyq",
        "outputId": "84e6558c-3eb4-4312-d9f2-b0dc9e719442"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total images: 13485  | Classes: ['fish_01', 'fish_07', 'fish_04', 'fish_03', 'fish_05', 'fish_02']\n",
            "\n",
            "========================\n",
            "      FOLD 1\n",
            "========================\n",
            "Found 6742 images belonging to 6 classes.\n",
            "Found 6743 images belonging to 6 classes.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 284ms/step - accuracy: 0.7038 - loss: 0.7996 - val_accuracy: 0.0872 - val_loss: 5.1623\n",
            "Epoch 2/10\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 203ms/step - accuracy: 0.9004 - loss: 0.2910 - val_accuracy: 0.7246 - val_loss: 0.7763\n",
            "Epoch 3/10\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 220ms/step - accuracy: 0.9348 - loss: 0.1871 - val_accuracy: 0.9076 - val_loss: 0.2524\n",
            "Epoch 4/10\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 202ms/step - accuracy: 0.9343 - loss: 0.1792 - val_accuracy: 0.9540 - val_loss: 0.1345\n",
            "Epoch 5/10\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 201ms/step - accuracy: 0.9520 - loss: 0.1390 - val_accuracy: 0.9600 - val_loss: 0.1110\n",
            "Epoch 6/10\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 201ms/step - accuracy: 0.9650 - loss: 0.1056 - val_accuracy: 0.9623 - val_loss: 0.1098\n",
            "Epoch 7/10\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 201ms/step - accuracy: 0.9626 - loss: 0.1081 - val_accuracy: 0.9576 - val_loss: 0.1261\n",
            "Epoch 8/10\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 203ms/step - accuracy: 0.9621 - loss: 0.1117 - val_accuracy: 0.9818 - val_loss: 0.0573\n",
            "Epoch 9/10\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 204ms/step - accuracy: 0.9731 - loss: 0.0901 - val_accuracy: 0.9779 - val_loss: 0.0685\n",
            "Epoch 10/10\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 199ms/step - accuracy: 0.9736 - loss: 0.0839 - val_accuracy: 0.9869 - val_loss: 0.0390\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "========================\n",
            "      FOLD 2\n",
            "========================\n",
            "Found 6743 images belonging to 6 classes.\n",
            "Found 6742 images belonging to 6 classes.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 275ms/step - accuracy: 0.6969 - loss: 0.8017 - val_accuracy: 0.2345 - val_loss: 4.4761\n",
            "Epoch 2/10\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 202ms/step - accuracy: 0.9036 - loss: 0.2827 - val_accuracy: 0.6688 - val_loss: 1.0019\n",
            "Epoch 3/10\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 219ms/step - accuracy: 0.9402 - loss: 0.1797 - val_accuracy: 0.8437 - val_loss: 0.5243\n",
            "Epoch 4/10\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 200ms/step - accuracy: 0.9495 - loss: 0.1501 - val_accuracy: 0.9257 - val_loss: 0.2144\n",
            "Epoch 5/10\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 203ms/step - accuracy: 0.9607 - loss: 0.1096 - val_accuracy: 0.9643 - val_loss: 0.1030\n",
            "Epoch 6/10\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 205ms/step - accuracy: 0.9657 - loss: 0.0924 - val_accuracy: 0.9462 - val_loss: 0.1725\n",
            "Epoch 7/10\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 206ms/step - accuracy: 0.9698 - loss: 0.0983 - val_accuracy: 0.9821 - val_loss: 0.0603\n",
            "Epoch 8/10\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 205ms/step - accuracy: 0.9689 - loss: 0.0827 - val_accuracy: 0.9733 - val_loss: 0.0881\n",
            "Epoch 9/10\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 204ms/step - accuracy: 0.9659 - loss: 0.0934 - val_accuracy: 0.9789 - val_loss: 0.0727\n",
            "Epoch 10/10\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 206ms/step - accuracy: 0.9767 - loss: 0.0746 - val_accuracy: 0.9580 - val_loss: 0.1169\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 44ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Cross-validation completed!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# CONFIG\n",
        "# -------------------------------------------------------\n",
        "IMG_SIZE = (128,128)\n",
        "BATCH_SIZE = 32\n",
        "K = 2    # number of folds\n",
        "save_dir = \"/content/resnet_kfold_results\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# LOAD DATASET STRUCTURE\n",
        "# -------------------------------------------------------\n",
        "all_images = []\n",
        "class_names = os.listdir(new_dataset_path)\n",
        "\n",
        "for cls in class_names:\n",
        "    class_path = os.path.join(new_dataset_path, cls)\n",
        "    if not os.path.isdir(class_path):\n",
        "        continue\n",
        "    for img in os.listdir(class_path):\n",
        "        all_images.append((os.path.join(class_path, img), cls))\n",
        "\n",
        "all_images = np.array(all_images)\n",
        "print(\"Total images:\", len(all_images), \" | Classes:\", class_names)\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# BUILD RESNET-18\n",
        "# -------------------------------------------------------\n",
        "def conv_block(x, filters, stride=1):\n",
        "    shortcut = x\n",
        "\n",
        "    # First conv\n",
        "    x = layers.Conv2D(filters, 3, strides=stride, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    # Second conv\n",
        "    x = layers.Conv2D(filters, 3, strides=1, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    # Match dimensions\n",
        "    if stride != 1:\n",
        "        shortcut = layers.Conv2D(filters, 1, strides=stride)(shortcut)\n",
        "        shortcut = layers.BatchNormalization()(shortcut)\n",
        "\n",
        "    x = layers.Add()([x, shortcut])\n",
        "    x = layers.ReLU()(x)\n",
        "    return x\n",
        "\n",
        "def build_resnet18(num_classes):\n",
        "    inputs = layers.Input(shape=(128,128,3))\n",
        "\n",
        "    x = layers.Conv2D(64, 7, strides=2, padding=\"same\")(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "    # ResNet-18 blocks\n",
        "    x = conv_block(x, 64)\n",
        "    x = conv_block(x, 64)\n",
        "\n",
        "    x = conv_block(x, 128, stride=2)\n",
        "    x = conv_block(x, 128)\n",
        "\n",
        "    x = conv_block(x, 256, stride=2)\n",
        "    x = conv_block(x, 256)\n",
        "\n",
        "    x = conv_block(x, 512, stride=2)\n",
        "    x = conv_block(x, 512)\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(256, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# K-FOLD TRAINING\n",
        "# -------------------------------------------------------\n",
        "kf = KFold(n_splits=K, shuffle=True, random_state=42)\n",
        "fold_no = 1\n",
        "metrics_list = []\n",
        "\n",
        "for train_index, test_index in kf.split(all_images):\n",
        "\n",
        "    print(f\"\\n========================\")\n",
        "    print(f\"      FOLD {fold_no}\")\n",
        "    print(f\"========================\")\n",
        "\n",
        "    fold_folder = os.path.join(save_dir, f\"fold_{fold_no}\")\n",
        "    os.makedirs(fold_folder, exist_ok=True)\n",
        "\n",
        "    train_files = all_images[train_index]\n",
        "    test_files = all_images[test_index]\n",
        "\n",
        "    temp_train = os.path.join(save_dir, f\"temp_train_{fold_no}\")\n",
        "    temp_test = os.path.join(save_dir, f\"temp_test_{fold_no}\")\n",
        "    os.makedirs(temp_train, exist_ok=True)\n",
        "    os.makedirs(temp_test, exist_ok=True)\n",
        "\n",
        "    for cls in class_names:\n",
        "        os.makedirs(os.path.join(temp_train, cls), exist_ok=True)\n",
        "        os.makedirs(os.path.join(temp_test, cls), exist_ok=True)\n",
        "\n",
        "    for filepath, cls in train_files:\n",
        "        shutil.copy(filepath, os.path.join(temp_train, cls))\n",
        "\n",
        "    for filepath, cls in test_files:\n",
        "        shutil.copy(filepath, os.path.join(temp_test, cls))\n",
        "\n",
        "    # DATA AUGMENTATION\n",
        "    train_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        rotation_range=20,\n",
        "        zoom_range=0.2,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        horizontal_flip=True\n",
        "    )\n",
        "\n",
        "    test_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    train_data = train_gen.flow_from_directory(\n",
        "        temp_train,\n",
        "        target_size=IMG_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode=\"categorical\"\n",
        "    )\n",
        "\n",
        "    test_data = test_gen.flow_from_directory(\n",
        "        temp_test,\n",
        "        target_size=IMG_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode=\"categorical\",\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    # BUILD MODEL\n",
        "    model = build_resnet18(len(class_names))\n",
        "\n",
        "    # TRAIN\n",
        "    history = model.fit(\n",
        "        train_data,\n",
        "        epochs=10,\n",
        "        validation_data=test_data,\n",
        "        verbose=1\n",
        "    )\n",
        "    history_df = pd.DataFrame(history.history)\n",
        "    history_df.to_csv(os.path.join(fold_folder, \"training_history.csv\"), index=False)\n",
        "\n",
        "    # Plot Accuracy Curve\n",
        "    plt.figure(figsize=(8,5))\n",
        "    plt.plot(history.history['accuracy'], label='Train Acc')\n",
        "    plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
        "    plt.title(f\"Accuracy Curve - Fold {fold_no}\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.savefig(os.path.join(fold_folder, \"accuracy_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Plot Loss Curve\n",
        "    plt.figure(figsize=(8,5))\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "    plt.title(f\"Loss Curve - Fold {fold_no}\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.savefig(os.path.join(fold_folder, \"loss_curve.png\"))\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "    # PREDICT\n",
        "    y_true = test_data.classes\n",
        "    y_pred = np.argmax(model.predict(test_data), axis=1)\n",
        "    labels = list(test_data.class_indices.keys())\n",
        "\n",
        "    # METRICS\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred, average=\"macro\")\n",
        "    rec = recall_score(y_true, y_pred, average=\"macro\")\n",
        "    f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
        "\n",
        "    metrics_list.append([fold_no, acc, prec, rec, f1])\n",
        "\n",
        "    # SAVE REPORT\n",
        "    with open(os.path.join(fold_folder, \"classification_report.txt\"), \"w\") as f:\n",
        "        f.write(classification_report(y_true, y_pred, target_names=labels))\n",
        "\n",
        "    # CONFUSION MATRIX\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(10,7))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
        "    plt.title(f\"Confusion Matrix - Fold {fold_no}\")\n",
        "    plt.savefig(os.path.join(fold_folder, \"confusion_matrix.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # SAVE MODEL\n",
        "    model.save(os.path.join(fold_folder, \"resnet18_model.h5\"))\n",
        "\n",
        "    # CLEAN\n",
        "    shutil.rmtree(temp_train)\n",
        "    shutil.rmtree(temp_test)\n",
        "\n",
        "    fold_no += 1\n",
        "\n",
        "# SUMMARY CSV\n",
        "df = pd.DataFrame(metrics_list, columns=[\"Fold\",\"Accuracy\",\"Precision\",\"Recall\",\"F1\"])\n",
        "df.to_csv(os.path.join(save_dir, \"summary_metrics.csv\"), index=False)\n",
        "\n",
        "print(\"\\nCross-validation completed!\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
